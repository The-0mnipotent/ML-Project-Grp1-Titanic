{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic_Problem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The-0mnipotent/ML-Project-Grp1-Titanic/blob/main/Titanic_Problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKzoCDh2aQ11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "cc1a52da-eab2-4680-b5de-d56ac55dcfbf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "a = pd.read_csv('train.csv')\n",
        "b = pd.read_csv('test.csv')\n",
        "\n",
        "e = pd.DataFrame({'PassengerId': b.PassengerId})\n",
        "\n",
        "a.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-86baab15eae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a['Cabin'].isnull().sum())\n",
        "print(a['Cabin'].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "bZS9_I6fJ61m",
        "outputId": "5bdfd42a-1817-4a08-eba8-f6a314dc6abb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2e776ac2bb4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cabin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cabin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = a.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\n",
        "b = b.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\n",
        "\n",
        "a.head()"
      ],
      "metadata": {
        "id": "nqX5jKMdKULN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.hist(column='Fare', bins=20)"
      ],
      "metadata": {
        "id": "uG9EdHmL2uaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def f0(row):\n",
        "  if row['Fare']<=90:\n",
        "    value=0\n",
        "  else:\n",
        "    value=1\n",
        "  return value\n",
        "\n",
        "a['Fare'] = a.apply(f0, axis=1)\n",
        "\n",
        "b['Fare'] = b.apply(f0, axis=1)\n"
      ],
      "metadata": {
        "id": "K3oFCGO5npuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a['Cabin'] = pd.factorize(a['Cabin'])[0]\n",
        "a['Sex'] = pd.factorize(a['Sex'])[0]\n",
        "\n",
        "b['Cabin'] = pd.factorize(b['Cabin'])[0]\n",
        "b['Sex'] = pd.factorize(b['Sex'])[0]\n",
        "\n",
        "def f(row):\n",
        "  if row['Cabin']==-1:\n",
        "    value=0\n",
        "  else:\n",
        "    value=1\n",
        "  return value\n",
        "\n",
        "a['Cabin_Exists'] = a.apply(f, axis=1)\n",
        "b['Cabin_Exists'] = b.apply(f, axis=1)\n",
        "\n",
        "a.head()"
      ],
      "metadata": {
        "id": "qtHvj_w3Lcfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = a.drop(['Cabin'], axis=1)\n",
        "b = b.drop(['Cabin'], axis=1)\n",
        "a.corr()"
      ],
      "metadata": {
        "id": "77fRsVx6YJGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1(row):\n",
        "  value = row['SibSp'] + row['Parch']\n",
        "  return value\n",
        "\n",
        "a['Family'] = a.apply(f1, axis=1)\n",
        "b['Family'] = b.apply(f1, axis=1)\n",
        "\n",
        "a = a.drop(['SibSp', 'Parch'], axis=1)\n",
        "b = b.drop(['SibSp', 'Parch'], axis=1)\n",
        "\n",
        "a.head()"
      ],
      "metadata": {
        "id": "ODyU6qetYuBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# split data\n",
        "train = a.loc[(a['Age'].notnull())]  # known age values\n",
        "test = a.loc[(a['Age'].isnull())]  # all nan age values\n",
        "\n",
        "train_b = b.loc[(b['Age'].notnull())]  # known age values\n",
        "test_b = b.loc[(b['Age'].isnull())]  # all nan age values\n",
        "\n",
        "# select age column\n",
        "y = train.values[:, 3]\n",
        "y_b = train_b.values[:, 2]\n",
        "\n",
        "# select pclass, fare and family\n",
        "X = train.values[:, [1, 7]]\n",
        "X_b = train_b.values[:, [0, 6]]\n",
        "\n",
        "# create RandomForestRegressor model\n",
        "rfr = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=7)\n",
        "\n",
        "# Fit a model\n",
        "rfr.fit(X, y)\n",
        "rfr.fit(X_b, y_b)\n",
        "\n",
        "# Use the fitted model to predict the missing values\n",
        "predictedAges = rfr.predict(test.values[:, [1, 7]])\n",
        "\n",
        "predictedAges_b = rfr.predict(test_b.values[:, [0, 6]])\n",
        "\n",
        "# create predicted age column\n",
        "a['pred_age'] = a['Age']\n",
        "\n",
        "b['pred_age'] = b['Age']\n",
        "\n",
        "\n",
        "# fill column\n",
        "a.loc[(a['pred_age'].isnull()), 'pred_age'] = predictedAges \n",
        "\n",
        "b.loc[(b['pred_age'].isnull()), 'pred_age'] = predictedAges_b \n",
        "\n",
        "\n",
        "a = a.drop(['Age'], axis=1)\n",
        "\n",
        "b = b.drop(['Age'], axis=1)\n",
        "\n",
        "a.head()"
      ],
      "metadata": {
        "id": "D5u1mCBMbFvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a['Embarked'] = a['Embarked'].fillna(a['Embarked'].mode()[0])\n",
        "a['Embarked'] = pd.factorize(a['Embarked'])[0]\n",
        "\n",
        "b['Embarked'] = b['Embarked'].fillna(b['Embarked'].mode()[0])\n",
        "b['Embarked'] = pd.factorize(b['Embarked'])[0]\n",
        "\n",
        "# a = a.drop('Embarked', axis=1)\n",
        "# b = b.drop('Embarked', axis=1)\n"
      ],
      "metadata": {
        "id": "8uVvS76lsOb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.isnull().sum()"
      ],
      "metadata": {
        "id": "qK7B-7XPnztZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.corr()"
      ],
      "metadata": {
        "id": "hKPUC_icZZvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.hist(column='pred_age', bins=20)\n"
      ],
      "metadata": {
        "id": "VKMhdw8wNhCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.groupby('pred_age')['Survived'].mean().plot(kind='bar', figsize=(25,9))\n"
      ],
      "metadata": {
        "id": "ewgxZSG-vbZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f2(row):\n",
        "  if row['pred_age']<=13:\n",
        "    value=0#infant\n",
        "  elif row['pred_age']<=60:\n",
        "    value=1#young\n",
        "  else:\n",
        "    value=2 #old\n",
        "  return value\n",
        "\n",
        "a['pred_age'] = a.apply(f2, axis=1)\n",
        "\n",
        "b['pred_age'] = b.apply(f2, axis=1)\n",
        "\n",
        "a.head()"
      ],
      "metadata": {
        "id": "BzgNjwyaSQqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = a['Survived']\n",
        "a = a.drop(['Survived'], axis=1)\n",
        "\n",
        "c.head()"
      ],
      "metadata": {
        "id": "CqQrwpGRuB-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(a,c,test_size=0.3,random_state=7)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler=StandardScaler()\n",
        "\n",
        "scaler.fit(X_train)\n",
        "\n",
        "scaled_X_train=scaler.transform(X_train)\n",
        "scaled_X_test=scaler.transform(X_test)\n",
        "\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#Create KNN Classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=7)\n"
      ],
      "metadata": {
        "id": "58DKWwG8dsUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# knn_params = {'n_neighbors':list(range(3,11))}\n",
        "\n",
        "# GS1 = GridSearchCV(knn, knn_params, cv = kf, scoring='accuracy')\n",
        "\n",
        "# GS1.fit(scaled_X_train, y_train)\n",
        "\n",
        "# print(GS1.best_params_)\n",
        "\n",
        "# print(GS1.best_score_)"
      ],
      "metadata": {
        "id": "v9R6AzTdcUOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# kf = KFold(n_splits=10, shuffle=True, random_state=7)\n",
        " \n",
        "# result = cross_val_score(knn , scaled_X_train, y_train, cv = kf)\n",
        " \n",
        "# print(result.mean())\n"
      ],
      "metadata": {
        "id": "VtP71YJeZVar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "result = cross_val_score(logreg , scaled_X_train, y_train, cv = kf)\n",
        " \n",
        "print(result.mean())\n",
        " "
      ],
      "metadata": {
        "id": "3GYSeiSkX_PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb_clf = GradientBoostingClassifier(n_estimators=120, learning_rate=0.3, max_depth=9, random_state=7)\n",
        "\n",
        "# GB_params = {'n_estimators': [20, 60, 120, 180], 'learning_rate': [0.05, 0.1, 0.2, 0.3, 0.4, 0.5], 'max_depth': list(range(5, 12))}\n",
        "\n",
        "# GS3 = GridSearchCV(gb_clf, GB_params, cv = kf, scoring='accuracy')\n",
        "\n",
        "# GS3.fit(scaled_X_train, y_train)\n",
        "\n",
        "# print(GS3.best_params_)\n",
        "\n",
        "# print(GS3.best_score_) \n",
        "\n"
      ],
      "metadata": {
        "id": "94objwKcarC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clfRF = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=9, bootstrap=True, n_jobs=-1, random_state=7)\n"
      ],
      "metadata": {
        "id": "UBam3idmqTaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# kf = KFold(n_splits=10, shuffle=True, random_state=7)\n",
        "\n",
        "\n",
        "# RF_params = {'n_estimators': [100, 300, 500, 800, 1000], 'criterion': ['gini', 'entropy'], 'max_depth': list(range(5, 12))}\n",
        "\n",
        "# GS2 = GridSearchCV(clfRF, RF_params, cv = kf, scoring='accuracy')\n",
        "\n",
        "# GS2.fit(scaled_X_train, y_train)\n",
        "\n",
        "# print(GS2.best_params_)\n",
        "\n",
        "# print(GS2.best_score_)\n",
        "\n"
      ],
      "metadata": {
        "id": "0OL3rFeQgnyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(8,10,8), activation='relu', solver='adam', max_iter=500)\n",
        "\n",
        "#cross validation\n",
        " \n",
        "result = cross_val_score(mlp , scaled_X_train, y_train, cv = kf)\n",
        " \n",
        "print(result.mean())"
      ],
      "metadata": {
        "id": "YYuWBipobIHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "\n",
        "clf = VotingClassifier(estimators = [('knn', knn), ('GB', gb_clf), ('RFC', clfRF), ('LR', logreg), ('MLP', mlp)], voting = 'hard')\n",
        "\n",
        "clf = clf.fit(scaled_X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(scaled_X_test)\n",
        "\n",
        "#cross-validation\n",
        " \n",
        "result = cross_val_score(clf , scaled_X_train, y_train, cv = kf)\n",
        " \n",
        "print(result.mean())"
      ],
      "metadata": {
        "id": "q35EL8ytimUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "xWbRu0P8EJ6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_b = scaler.transform(b)\n",
        "# test_pred = clf.predict(test_b)\n",
        "\n",
        "# output = pd.DataFrame({'PassengerId': e.PassengerId, 'Survived': test_pred})\n",
        "# print(output)\n",
        "# output.to_csv('submission.csv', index=False)\n",
        "\n",
        "# print(\"Submission saved\")"
      ],
      "metadata": {
        "id": "C2wvZ_CRrw2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ItUosiy_urIN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}